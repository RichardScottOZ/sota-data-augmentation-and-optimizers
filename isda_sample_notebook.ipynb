{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEA54XugEGif"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL \n",
    "import time \n",
    "import torch \n",
    "import torchvision \n",
    "import random\n",
    "\n",
    "import numpy as np \n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn.functional as F\n",
    "\n",
    "#data transforms\n",
    "from torch.autograd import Variable \n",
    "from torchvision import datasets, transforms \n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "#data aug\n",
    "from augmentation.autoaugment import CIFAR10Policy \n",
    "from augmentation.cutout import Cutout \n",
    "from augmentation.AugMix.AugMix import AugMixDataset \n",
    "from augmentation.RandAugment import RandAugment\n",
    "\n",
    "#optim and activation\n",
    "from optim.deepmemory   import DeepMemory\n",
    "from optim.lookahead    import Lookahead \n",
    "from optim.radam        import RAdam \n",
    "from adamod       import AdaMod\n",
    "from activations  import Mish\n",
    "\n",
    "from augmentation.ISDA import ISDALoss\n",
    "\n",
    "from loss_func.cross_entropy import CrossEntropyLoss #https://github.com/eladhoffer/utils.pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFd6_1FaC8IJ"
   },
   "source": [
    "### Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16jaSKCbC8IK"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    \n",
    "set_seed(72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhpsmnD9C8IN"
   },
   "source": [
    "### Preprocess and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9gccw6eC8IO"
   },
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (.2023, .1994, .2010)),  #CIFAR10\n",
    "#      transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))      #CIFAR100\n",
    "#      Cutout(n_holes=1, length=16),               # CutOut\n",
    "])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4, fill=128),\n",
    "#     CIFAR10Policy(),                    # AutoAugment\n",
    "    preprocess\n",
    "\n",
    "])\n",
    "\n",
    "# train_transform.transforms.insert(0, RandAugment(1, 5))                    #RandAugment\n",
    "\n",
    "test_transform = preprocess\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.4914, 0.4822, 0.4465), (.2023, .1994, .2010)),  #CIFAR10\n",
    "#      transforms.Normalize((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))      #CIFAR100\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5368,
     "status": "ok",
     "timestamp": 1578408490076,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "1xp_0nfnC8IS",
    "outputId": "c428f62b-7480-424f-98fa-655a7fb8a893"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_data = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
    "\n",
    "test_data= datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "# load training data in batches\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "#                       AugMixDataset(train_data, preprocess, no_jsd=True),      # Augmix\n",
    "                      train_data,\n",
    "                      batch_size=batch_size,\n",
    "                      num_workers=8,\n",
    "                      shuffle=True, \n",
    "                      pin_memory=True\n",
    "                      )\n",
    "\n",
    "# load test data in batches\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                      batch_size=batch_size,\n",
    "                      num_workers=8,\n",
    "                      shuffle=False,\n",
    "                      pin_memory=True\n",
    "                      )\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5956,
     "status": "ok",
     "timestamp": 1578408490675,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "j-Pyw7pDC8IV",
    "outputId": "d20e99b7-379a-47e8-8bf0-566f4b580375"
   },
   "outputs": [],
   "source": [
    "print(f'Length of train loader is {len(train_loader)}')\n",
    "print(f'Length of test loader is {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vL7xtpfgC8IY"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkrOlRjZC8IZ"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5F0pZ3oGNn8"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjw4M_ghC8Id"
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):        \n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        # Depthwise Convolutions\n",
    "        self.layers = nn.Sequential(\n",
    "                            nn.Conv2d(in_channels=1*3, out_channels=16*3, kernel_size=3, groups=1, stride=1, padding=1, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=16*3, eps=1e-3, momentum=0.99),\n",
    "                                                      \n",
    "                            nn.Conv2d(in_channels=16*3, out_channels=96, kernel_size=1, groups=8, stride=1, padding=0, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=96, eps=1e-3, momentum=0.99),\n",
    "                                    \n",
    "                            nn.Conv2d(in_channels=96, out_channels=128, kernel_size=3, groups=8, stride=1, padding=1, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=128, eps=1e-3, momentum=0.99),\n",
    "                            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "                            nn.Conv2d(in_channels=128, out_channels=192, kernel_size=1, groups=16, stride=1, padding=0, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=192, eps=1e-3, momentum=0.99),\n",
    "                                                        \n",
    "                            nn.Conv2d(in_channels=192, out_channels=256, kernel_size=3, groups=16, stride=1, padding=1, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=256, eps=1e-3, momentum=0.99),\n",
    "                                                                                                                \n",
    "                            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=1, groups=32, stride=1, padding=0, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=512, eps=1e-3, momentum=0.99),\n",
    "                            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "                            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, groups=64, stride=1, padding=1, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=512, eps=1e-3, momentum=0.99),\n",
    "                                                        \n",
    "                            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, groups=16, stride=1, padding=0, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=256, eps=1e-3, momentum=0.99),\n",
    "\n",
    "                            nn.Conv2d(in_channels=256, out_channels=192, kernel_size=3, groups=16, stride=1, padding=1, bias=False),\n",
    "                            Mish(),\n",
    "                            nn.BatchNorm2d(num_features=192, eps=1e-3, momentum=0.99),\n",
    "                            nn.MaxPool2d(2, 2),\n",
    "                            )\n",
    "        \n",
    "        \n",
    "        #squeeze and excitation\n",
    "        self.se_reduce = nn.Conv2d(in_channels=192, out_channels=128, kernel_size=1)\n",
    "        self.se_expand = nn.Conv2d(in_channels=128, out_channels=192, kernel_size=1)\n",
    "        \n",
    "        # fully connected layer\n",
    "        # self.fc = nn.Linear(in_features=192*4*4, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x_squeezed = F.adaptive_avg_pool2d(x, x.size(2))\n",
    "        x_squeezed = self.se_expand(Mish()(self.se_reduce(x_squeezed)))\n",
    "        x = torch.sigmoid(x_squeezed) * x\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "            \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_rrxfS8C8If"
   },
   "outputs": [],
   "source": [
    "class Full_layer(torch.nn.Module):\n",
    "    '''explicitly define the full connected layer'''\n",
    "\n",
    "    def __init__(self, feature_num, class_num):\n",
    "        super(Full_layer, self).__init__()\n",
    "        self.class_num = class_num\n",
    "        self.fc = nn.Linear(feature_num, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbyc6OWovS1Z"
   },
   "outputs": [],
   "source": [
    "feature_num = 192*4*4\n",
    "num_classes = len(classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model = torch.nn.DataParallel(model)\n",
    "fc = Full_layer(feature_num, num_classes).to(device)\n",
    "fc = torch.nn.DataParallel(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2NXdJ8QmC8Il"
   },
   "outputs": [],
   "source": [
    "best_top1 = 0 # train from start\n",
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5881,
     "status": "ok",
     "timestamp": 1578408490683,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "_pAMhiaGC8In",
    "outputId": "fc495552-9bee-4e07-b560-9952bba23311"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "combine_ratio = 0.5\n",
    "isda_criterion = ISDALoss(feature_num, num_classes)\n",
    "ce_criterion = CrossEntropyLoss(smooth_eps=0.1).to(device)\n",
    "optimizer = Lookahead(DeepMemory([{'params': model.parameters()},\n",
    "                             {'params': fc.parameters()}], len_memory=len(train_data.data)//batch_size))          # rectified adam wtih lookahead\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_data.data)//batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5821,
     "status": "ok",
     "timestamp": 1578408490684,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "-G3hRhKjC8Iq",
    "outputId": "c9c30ba7-d6f5-425b-a91d-ff67079e520a"
   },
   "outputs": [],
   "source": [
    "print('Number of model parameters: {}'.format(\n",
    "        sum([p.data.nelement() for p in model.parameters()]) +\n",
    "        sum([p.data.nelement() for p in fc.parameters()])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C14QGjdlC8Is"
   },
   "source": [
    "### Load Checkpoints to resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZpQxfxoC8It"
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('./checkpoint/CustomModel_standard_dmla_isda_ckpt.pth')\n",
    "\n",
    "# model.module.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# fc.module.load_state_dict(checkpoint['fc'])\n",
    "# start_epoch = checkpoint['epoch']\n",
    "# best_loss = checkpoint['loss']\n",
    "# best_top1 = checkpoint['top1']   # resume training\n",
    "# best_top5 = checkpoint['top5']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyF3ZvbcC8Iv"
   },
   "outputs": [],
   "source": [
    "# print(f'Top-1 Acc: {best_top1}\\t Top-5 Acc: {best_top5}\\t Best loss: {best_loss:.4f}\\t Best epoch: {start_epoch}')\n",
    "# print(f'Loaded checkpoint with \\n {best_top1}% Top-1 Accuracy, {best_top5}% Top-5 Accuracy, after training for {start_epoch} epochs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t5qbmlttC8I0"
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5793,
     "status": "ok",
     "timestamp": 1578408490686,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "ItbiKWAqC8I1",
    "outputId": "0965e05f-1129-4722-856e-6e7bfcf36933"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def train(train_loader, model, fc, criterion, optimizer, epoch):\n",
    "    print('Training model...\\n')\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    ratio = combine_ratio * (epoch / (num_epochs))\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    fc.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "                \n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        \n",
    "        target = target.to(device)\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute output\n",
    "        loss, output = criterion(model, fc, input_var, target_var, ratio)\n",
    "                  \n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 1500 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses, top1=top1, top5=top5))\n",
    "    \n",
    "    print(' * Acc@1 {top1.avg:.3f} Acc@1 Error {top1_err:.3f}\\n'\n",
    "              ' * Acc@5 {top5.avg:.3f} Acc@5 Error {top5_err:.3f}'\n",
    "              .format(top1=top1, top1_err=100-top1.avg, top5=top5, top5_err=100-top5.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJM2KylGC8I3"
   },
   "source": [
    "### Accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5783,
     "status": "ok",
     "timestamp": 1578408490687,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "XU8O4IeqC8I4",
    "outputId": "2c19b78a-8199-4241-9e1b-912afcc284fd"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def validate(test_loader, model, fc, criterion, epoch):\n",
    "    print('Evaluating model on test data...\\n')\n",
    "    \n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    \n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    fc.eval()\n",
    "        \n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(test_loader):\n",
    "        target = target.to(device)\n",
    "        input_var = Variable(input)\n",
    "        target_var = Variable(target)\n",
    "\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            features = model(input_var)\n",
    "            output = fc(features)\n",
    "            \n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target.data, topk=(1, 5))\n",
    "        losses.update(loss.data.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "        top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 250 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(test_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "\n",
    "\n",
    "\n",
    "    print(' * Acc@1 {top1.avg:.3f} Acc@1 Error {top1_err:.3f}\\n'\n",
    "          ' * Acc@5 {top5.avg:.3f} Acc@5 Error {top5_err:.3f}'\n",
    "          .format(top1=top1, top1_err=100-top1.avg, top5=top5, top5_err=100-top5.avg))\n",
    "\n",
    "    return top1, top5, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PENtGnGPC8I9"
   },
   "source": [
    "### Checkpoint Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32375,
     "status": "error",
     "timestamp": 1578051783181,
     "user": {
      "displayName": "Enoch Tetteh",
      "photoUrl": "",
      "userId": "18429685187145851841"
     },
     "user_tz": -120
    },
    "id": "-L24-Ar-C8I-",
    "outputId": "df73da99-22ad-4b8b-ba99-450209f9b8e1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    train(train_loader, model, fc, isda_criterion, optimizer, epoch)\n",
    "    top1, top5, losses = validate(test_loader, model, fc, ce_criterion, epoch)\n",
    "\n",
    "    if top1.avg > best_top1:\n",
    "        print('Saving checkpoint')\n",
    "        state = {\n",
    "            'model_state_dict': model.module.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'fc': fc.module.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': losses.avg, \n",
    "            'top1': top1.avg,\n",
    "            'top5': top5.avg}\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/CustomModel_standard_dmla_isda_ckpt.pth')\n",
    "\n",
    "        best_top1 = top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfpsnSy5C8JB"
   },
   "source": [
    "### Accuracy for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrjsygnhC8JB"
   },
   "outputs": [],
   "source": [
    "# class_correct = list(0. for i in range(100))\n",
    "# class_total = list(0. for i in range(100))\n",
    "# with torch.no_grad():\n",
    "#     for data in test_loader:\n",
    "#         images, labels = data\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs, 1)\n",
    "#         c = (predicted == labels).squeeze()\n",
    "#         for i in range(4):\n",
    "#             label = labels[i]\n",
    "#             class_correct[label] += c[i].item()\n",
    "#             class_total[label] += 1\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "#     print('Accuracy of %5s : %2d %%' % (\n",
    "#         classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3tSREZ7NsyM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
